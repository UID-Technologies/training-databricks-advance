
# â­ **Lab 07 â€” Building Lakeflow Declarative Pipelines (Advanced)**

---

# ğŸ§ª **Lab 3.1 â€“ Streaming Joins Overview**

### Step 1 â€” Create streaming customers and orders

YAML:

```yaml
datasets:
  streaming_orders:
    type: streaming_live_table
    source:
      type: cloud_files
      path: "dbfs:/FileStore/lakeflow/data/orders_stream"
      schema: auto

  customers_silver:
    type: live_table
    format: json
    path: "dbfs:/FileStore/lakeflow/data/customers"

  orders_enriched:
    type: live_table
    sources:
      - streaming_orders
      - customers_silver
    transformation:
      join:
        left: "streaming_orders"
        right: "customers_silver"
        on: "streaming_orders.customer_id = customers_silver.customer_id"
```

---

# ğŸ§ª **Lab 3.2 â€“ Deploy Pipeline to Production**

### Step 1 â€” Promote pipeline from dev â†’ prod

Trainer explains:

Production uses:

* Job clusters
* Versioned YAML
* CI/CD (Git + Repos)

Steps:

1. Publish YAML to Git repository.
2. Connect Repo in Databricks.
3. Deploy pipeline from repo path.
4. Configure proper compute.
5. Add schedule (hourly/daily).
6. Add alerts.

---

# ğŸ§ª **Lab 3.3 â€“ Change Data Capture (CDC) Overview**

Explain that:

* Lakeflow supports CDC via **CHANGE INTO** syntax.
* Used for upserts.

---

# ğŸ§ª **Lab 3.4 â€“ Hands-On: CDC Using CHANGE INTO**

### Step 1 â€” Create CDC source dataset

Upload CDC data:

`orders_cdc.csv`:

```
order_id,amount,_change_type
1,250,update
5,500,insert
3,NULL,delete
```

### Step 2 â€” Create CDC Pipeline

`orders_cdc_pipeline.yaml`

```yaml
pipeline_type: delta_live_tables

datasets:
  raw_cdc:
    type: dataset
    format: cloud_files
    path: "dbfs:/FileStore/lakeflow/data/cdc"

  orders_target:
    type: live_table
    source: raw_cdc
    apply_changes_into:
      target: training.silver.orders_cdc
      keys: ["order_id"]
      sequence_by: "_ingest_time"
      except_columns: ["_change_type"]
      apply_as_deletes:
        expression: "_change_type = 'delete'"
```

Deploy & validate:

```sql
SELECT * FROM training.silver.orders_cdc;
```

---

# ğŸ§ª **Lab 3.5 â€“ Additional Features Overview**

Trainer quickly demonstrates:

* Pipeline snapshots
* Auto-monitoring
* Error observability
* Catalog switching
* Using `materialized_view` for gold aggregates

---

# ğŸ‰ If you'd like next:

I can produce:

âœ… A full **PDF-ready Lab Manual**
âœ… A full **32-hour structured course**
âœ… A **project template** for students
âœ… **Slide deck** with diagrams
âœ… A **Git repo folder structure** for declarative pipelines

Just tell me **â€œCreate Lab Manual PDF packetâ€** or **â€œCreate slides for this moduleâ€**.
